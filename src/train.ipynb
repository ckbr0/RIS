{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "animated-timber",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-colonial",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import monai.networks.nets as nets\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    AddChanneld,\n",
    "    CropForegroundd,\n",
    "    ToTensord,\n",
    "    RandAxisFlipd,\n",
    "    RandAffined,\n",
    "    SpatialPadd,\n",
    "    Activationsd,\n",
    "    Resized,\n",
    ")\n",
    "from transforms import (\n",
    "    CTWindowd,\n",
    "    CTSegmentation,\n",
    "    RelativeCropZd,\n",
    "    RandGaussianNoised,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, PersistentDataset, CacheDataset\n",
    "from monai.transforms.croppad.batch import PadListDataCollate\n",
    "from monai.utils import NumpyPadMode, set_determinism\n",
    "from monai.utils.enums import Method\n",
    "from monai.config import print_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from trainer import Trainer\n",
    "from validator import Validator\n",
    "from tester import Tester\n",
    "from utils import (\n",
    "    setup_directories,\n",
    "    create_device,\n",
    "    get_data_from_info,\n",
    "    large_image_splitter,\n",
    "    calculate_class_imbalance,\n",
    "    balance_training_data,\n",
    ")\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-turkish",
   "metadata": {},
   "source": [
    "## Setup directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = setup_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-retro",
   "metadata": {},
   "source": [
    "## Setup torch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass \"cuda\" to use the GPU\n",
    "device, using_gpu = create_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-lemon",
   "metadata": {},
   "source": [
    "## Load and randomize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACKATON image and segmentation data\n",
    "hackathon_dir = os.path.join(dirs[\"data\"], 'HACKATHON')\n",
    "with open(os.path.join(hackathon_dir, \"train.txt\"), 'r') as fp:\n",
    "    train_info_hackathon = [entry.strip().split(',') for entry in fp.readlines()]\n",
    "image_dir = os.path.join(hackathon_dir, 'images', 'train')\n",
    "seg_dir = os.path.join(hackathon_dir, 'segmentations', 'train')\n",
    "_train_data_hackathon = get_data_from_info(image_dir, seg_dir, train_info_hackathon, dual_output=False)\n",
    "large_image_splitter(_train_data_hackathon, dirs[\"cache\"])\n",
    "balance_training_data(_train_data_hackathon, seed=72)\n",
    "# PSUF data\n",
    "\"\"\"psuf_dir = os.path.join(dirs[\"data\"], 'psuf')\n",
    "with open(os.path.join(psuf_dir, \"train.txt\"), 'r') as fp:\n",
    "    train_info = [entry.strip().split(',') for entry in fp.readlines()]\n",
    "image_dir = os.path.join(psuf_dir, 'images')\n",
    "train_data_psuf = get_data_from_info(image_dir, None, train_info)\"\"\"\n",
    "# Split data into train, validate and test\n",
    "train_split, test_data_hackathon = train_test_split(_train_data_hackathon, test_size=0.2, shuffle=True, random_state=42)\n",
    "train_data_hackathon, valid_data_hackathon = train_test_split(train_split, test_size=0.2, shuffle=True, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-alabama",
   "metadata": {},
   "source": [
    "## Setup transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop foreground\n",
    "crop_foreground = CropForegroundd(\n",
    "    keys=[\"image\"],\n",
    "    source_key=\"image\",\n",
    "    margin=(5, 5, 0),\n",
    "    select_fn = lambda x: x != 0\n",
    ")\n",
    "# Crop Z\n",
    "crop_z = RelativeCropZd(keys=[\"image\"], relative_z_roi=(0.05, 0.15))\n",
    "# Window width and level (window center)\n",
    "WW, WL = 1500, -600\n",
    "ct_window = CTWindowd(keys=[\"image\"], width=WW, level=WL)\n",
    "# Random flip axis\n",
    "rand_x_flip = RandFlipd(keys=[\"image\"], spatial_axis=0, prob=0.50)\n",
    "rand_y_flip = RandFlipd(keys=[\"image\"], spatial_axis=1, prob=0.50)\n",
    "rand_z_flip = RandFlipd(keys=[\"image\"], spatial_axis=2, prob=0.50)\n",
    "# Rand affine transform\n",
    "rand_affine = RandAffined(\n",
    "    keys=[\"image\"],\n",
    "    prob=0.50,\n",
    "    rotate_range=(0, 0, np.pi/12),\n",
    "    shear_range=(0.07, 0.07, 0.0),\n",
    "    translate_range=(0, 0, 0),\n",
    "    scale_range=(0.07, 0.07, 0.0),\n",
    "    padding_mode=\"zeros\"\n",
    ")\n",
    "# Pad image to have hight at least 30\n",
    "spatial_pad = SpatialPadd(keys=[\"image\"], spatial_size=(-1, -1, 30))\n",
    "# Resize image x and y\n",
    "resize_fator = 0.5\n",
    "resize = Resized(keys=[\"image\"], spatial_size=(int(512*resize_fator), int(512*resize_fator), -1), mode=\"trilinear\")\n",
    "# Apply Gaussian noise\n",
    "rand_gaussian_noise = RandGaussianNoised(keys=[\"image\"], prob=0.25, mean=0.0, std=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-perry",
   "metadata": {},
   "source": [
    "#### Create transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_transform = Compose([\n",
    "    LoadImaged(keys=[\"image\"]),\n",
    "    ct_window,\n",
    "    CTSegmentation(keys=[\"image\"]),\n",
    "    AddChanneld(keys=[\"image\"]),\n",
    "    resize,\n",
    "    crop_foreground,\n",
    "    crop_z,\n",
    "    spatial_pad,\n",
    "])\n",
    "hackathon_train_transform = Compose([\n",
    "    common_transform,\n",
    "    rand_x_flip,\n",
    "    rand_y_flip,\n",
    "    rand_z_flip,\n",
    "    rand_affine,\n",
    "    rand_gaussian_noise,\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "]).flatten()\n",
    "hackathon_valid_transfrom = Compose([\n",
    "    common_transform,\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "]).flatten()\n",
    "psuf_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\"]),\n",
    "    AddChanneld(keys=[\"image\"]),\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-humanity",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_determinism(seed=100)\n",
    "train_dataset = PersistentDataset(data=train_data_hackathon[:], transform=hackathon_train_transform, cache_dir=dirs[\"persistent\"])\n",
    "valid_dataset = PersistentDataset(data=valid_data_hackathon[:], transform=hackathon_valid_transfrom, cache_dir=dirs[\"persistent\"])\n",
    "test_dataset = PersistentDataset(data=test_data_hackathon[:], transform=hackathon_valid_transfrom, cache_dir=dirs[\"persistent\"])\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    pin_memory=using_gpu,\n",
    "    num_workers=2,\n",
    "    collate_fn=PadListDataCollate(Method.SYMMETRIC, NumpyPadMode.CONSTANT)\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    pin_memory=using_gpu,\n",
    "    num_workers=2,\n",
    "    collate_fn=PadListDataCollate(Method.SYMMETRIC, NumpyPadMode.CONSTANT)\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    pin_memory=using_gpu,\n",
    "    num_workers=2,\n",
    "    collate_fn=PadListDataCollate(Method.SYMMETRIC, NumpyPadMode.CONSTANT)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-premium",
   "metadata": {},
   "source": [
    "## Setup network, loss function, optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nets.DenseNet169(spatial_dims=3, in_channels=1, out_channels=1).to(device)\n",
    "# pos_weight for class imbalance\n",
    "pos_weight = calculate_class_imbalance(train_info_hackathon).to(device)\n",
    "loss_function = torch.nn.BCEWithLogitsLoss(pos_weight)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.2e-3, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-xerox",
   "metadata": {},
   "source": [
    "## Setup validator and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-peter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_post_transforms = Compose([\n",
    "    Activationsd(keys=\"pred\", sigmoid=True),\n",
    "    #Activationsd(keys=\"pred\", softmax=True),\n",
    "])\n",
    "validator = Validator(\n",
    "    device=device,\n",
    "    val_data_loader=valid_loader,\n",
    "    network=network,\n",
    "    post_transform=valid_post_transforms,\n",
    "    amp=using_gpu,\n",
    "    non_blocking=using_gpu\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    device=device,\n",
    "    out_dir=dirs[\"out\"],\n",
    "    out_name=\"DenseNet169\",\n",
    "    max_epochs=120,\n",
    "    train_data_loader=train_loader,\n",
    "    network=network,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    lr_scheduler=None,\n",
    "    validator=validator,\n",
    "    amp=using_gpu,\n",
    "    non_blocking=using_gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-afternoon",
   "metadata": {},
   "source": [
    "## Run trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-africa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_output = trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-finish",
   "metadata": {},
   "source": [
    "## Setup tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = Tester(\n",
    "    device=device,\n",
    "    test_data_loader=test_loader,\n",
    "    load_dir=train_output,\n",
    "    out_dir=dirs[\"out\"],\n",
    "    network=network,\n",
    "    post_transform=valid_post_transforms,\n",
    "    non_blocking=using_gpu,\n",
    "    amp=using_gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-portugal",
   "metadata": {},
   "source": [
    "## Run tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hairy-standing",
   "metadata": {},
   "source": [
    "## Setup inports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "falling-diana",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import monai.networks.nets as nets\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    AddChanneld,\n",
    "    CropForegroundd,\n",
    "    ToTensord,\n",
    "    RandAxisFlipd,\n",
    "    RandAffined,\n",
    "    SpatialPadd,\n",
    "    Activationsd,\n",
    "    Resized,\n",
    "    RandGaussianNoised,\n",
    ")\n",
    "from transforms import (\n",
    "    CTWindowd,\n",
    "    #RandCTWindowd,\n",
    "    CTSegmentation,\n",
    "    RelativeCropZd,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, PersistentDataset, CacheDataset\n",
    "from monai.transforms.croppad.batch import PadListDataCollate\n",
    "from monai.utils import NumpyPadMode, set_determinism\n",
    "from monai.utils.enums import Method\n",
    "from monai.config import print_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from trainer import Trainer\n",
    "from validator import Validator\n",
    "from tester import Tester\n",
    "from utils import multi_slice_viewer, setup_directories, get_data_from_info, large_image_splitter, calculate_class_imbalance, create_device, balance_training_data\n",
    "from test_data_loader import TestDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-african",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "personal-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_output):\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    print_config()\n",
    "\n",
    "    # Setup directories\n",
    "    dirs = setup_directories()\n",
    "\n",
    "    # Setup torch device\n",
    "    device, using_gpu = create_device(\"cuda\")\n",
    "\n",
    "    # Load and randomize images\n",
    "\n",
    "    # HACKATON image and segmentation data\n",
    "    hackathon_dir = os.path.join(dirs[\"data\"], 'HACKATHON')\n",
    "    map_fn = lambda x: (x[0], int(x[1]))\n",
    "    with open(os.path.join(hackathon_dir, \"train.txt\"), 'r') as fp:\n",
    "        train_info_hackathon = [map_fn(entry.strip().split(',')) for entry in fp.readlines()]\n",
    "    image_dir = os.path.join(hackathon_dir, 'images', 'train')\n",
    "    seg_dir = os.path.join(hackathon_dir, 'segmentations', 'train')\n",
    "    _train_data_hackathon = get_data_from_info(\n",
    "        image_dir, seg_dir, train_info_hackathon, dual_output=False\n",
    "    )\n",
    "    large_image_splitter(_train_data_hackathon, dirs[\"cache\"])\n",
    "\n",
    "    balance_training_data(_train_data_hackathon, seed=72)\n",
    "\n",
    "    # PSUF data\n",
    "    \"\"\"psuf_dir = os.path.join(dirs[\"data\"], 'psuf')\n",
    "    with open(os.path.join(psuf_dir, \"train.txt\"), 'r') as fp:\n",
    "        train_info = [entry.strip().split(',') for entry in fp.readlines()]\n",
    "    image_dir = os.path.join(psuf_dir, 'images')\n",
    "    train_data_psuf = get_data_from_info(image_dir, None, train_info)\"\"\"\n",
    "    # Split data into train, validate and test\n",
    "    train_split, test_data_hackathon = train_test_split(_train_data_hackathon, test_size=0.2, shuffle=True, random_state=42)\n",
    "    #train_data_hackathon, valid_data_hackathon = train_test_split(train_split, test_size=0.2, shuffle=True, random_state=43)\n",
    "    # Setup transforms\n",
    "\n",
    "    # Crop foreground\n",
    "    crop_foreground = CropForegroundd(\n",
    "        keys=[\"image\"],\n",
    "        source_key=\"image\",\n",
    "        margin=(5, 5, 0),\n",
    "        #select_fn = lambda x: x != 0\n",
    "    )\n",
    "    # Crop Z\n",
    "    crop_z = RelativeCropZd(keys=[\"image\"], relative_z_roi=(0.07, 0.12))\n",
    "    # Window width and level (window center)\n",
    "    WW, WL = 1500, -600\n",
    "    ct_window = CTWindowd(keys=[\"image\"], width=WW, level=WL)\n",
    "    spatial_pad = SpatialPadd(keys=[\"image\"], spatial_size=(-1, -1, 30))\n",
    "    resize = Resized(keys=[\"image\"], spatial_size=(int(512*0.50), int(512*0.50), -1), mode=\"trilinear\")\n",
    "    \n",
    "    # Create transforms\n",
    "    common_transform = Compose([\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        ct_window,\n",
    "        CTSegmentation(keys=[\"image\"]),\n",
    "        AddChanneld(keys=[\"image\"]),\n",
    "        resize,\n",
    "        crop_foreground,\n",
    "        crop_z,\n",
    "        spatial_pad,\n",
    "    ])\n",
    "    hackathon_train_transfrom = Compose([\n",
    "        common_transform,\n",
    "        ToTensord(keys=[\"image\"]),\n",
    "    ]).flatten()\n",
    "    psuf_transforms = Compose([\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        AddChanneld(keys=[\"image\"]),\n",
    "        ToTensord(keys=[\"image\"]),\n",
    "    ])\n",
    "\n",
    "    # Setup data\n",
    "    #set_determinism(seed=100)\n",
    "    test_dataset = PersistentDataset(data=test_data_hackathon[:], transform=hackathon_train_transfrom, cache_dir=dirs[\"persistent\"])\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        pin_memory=using_gpu,\n",
    "        num_workers=1,\n",
    "        collate_fn=PadListDataCollate(Method.SYMMETRIC, NumpyPadMode.CONSTANT)\n",
    "    )\n",
    "\n",
    "    # Setup network, loss function, optimizer and scheduler\n",
    "    network = nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=1).to(device)\n",
    "\n",
    "    # Setup validator and trainer\n",
    "    valid_post_transforms = Compose([\n",
    "        Activationsd(keys=\"pred\", sigmoid=True),\n",
    "    ])\n",
    "\n",
    "    # Setup tester\n",
    "    tester = Tester(\n",
    "        device=device,\n",
    "        test_data_loader=test_loader,\n",
    "        load_dir=train_output,\n",
    "        out_dir=dirs[\"out\"],\n",
    "        network=network,\n",
    "        post_transform=valid_post_transforms,\n",
    "        non_blocking=using_gpu,\n",
    "        amp=using_gpu\n",
    "    )\n",
    "\n",
    "    # Run tester\n",
    "    tester.run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chicken-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.5.0rc5+2.gc3dbb8a\n",
      "Numpy version: 1.19.5\n",
      "Pytorch version: 1.7.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: c3dbb8a46c3d38edeff65b33f287eb3fc1bd9f9d\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.4\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.18.1\n",
      "Pillow version: 8.1.2\n",
      "Tensorboard version: 2.4.1\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.8.2\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.59.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.8.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "Cuda device is not supported, switching to CPU\n",
      "Splitting large images...\n",
      "original data len: 355\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0001.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0022.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0011.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0016.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0008.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0015.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0021.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0009.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0020.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0012.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0014.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0002.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0019.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0000.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0017.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0006.nii.gz\n",
      "split image: /home/jupyter/RIS/data/HACKATHON/images/train/0018.nii.gz\n",
      "new data len: 400\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-63ba597c6a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-08504ec7faa1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_output)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mpost_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_post_transforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musing_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musing_gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RIS/src/tester.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device, test_data_loader, network, load_dir, out_dir, non_blocking, post_transform, amp, mode)\u001b[0m\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mload_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'network_key_metric*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         handlers = [\n\u001b[1;32m     49\u001b[0m             \u001b[0mStatsHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "automated-checkout",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import monai.networks.nets as nets\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    AddChanneld,\n",
    "    CropForegroundd,\n",
    "    ToTensord,\n",
    "    RandFlipd,\n",
    "    RandAffined,\n",
    "    SpatialPadd,\n",
    "    Activationsd,\n",
    "    Resized,\n",
    "    AsDiscreted,\n",
    "    AsDiscrete,\n",
    "    GaussianSmoothd,\n",
    "    SpatialCropd,\n",
    "    MeanEnsembled,\n",
    "    Activations,\n",
    ")\n",
    "from transforms import (\n",
    "    CTWindowd,\n",
    "    CTSegmentation,\n",
    "    RelativeCropZd,\n",
    "    RandGaussianNoised,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, PersistentDataset, CacheDataset\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from monai.transforms.croppad.batch import PadListDataCollate\n",
    "from monai.utils import NumpyPadMode, set_determinism\n",
    "from monai.utils.enums import Method\n",
    "from monai.config import print_config\n",
    "from monai.engines import EnsembleEvaluator\n",
    "from monai.handlers import ROCAUC, StatsHandler\n",
    "from ignite.metrics import Accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from trainer import Trainer\n",
    "from validator import Validator\n",
    "from tester import Tester\n",
    "from utils import (\n",
    "    multi_slice_viewer,\n",
    "    setup_directories,\n",
    "    get_data_from_info,\n",
    "    large_image_splitter,\n",
    "    calculate_class_imbalance,\n",
    "    create_device,\n",
    "    balance_training_data,\n",
    "    balance_training_data2,\n",
    "    transform_and_copy,\n",
    "    convert_labels,\n",
    "    load_mixed_images,\n",
    ")\n",
    "from test_data_loader import TestDataset\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-mention",
   "metadata": {},
   "source": [
    "## Setup directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = setup_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-fiber",
   "metadata": {},
   "source": [
    "## Setup torch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass \"cuda\" to use the GPU\n",
    "device, using_gpu = create_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-promise",
   "metadata": {},
   "source": [
    "## Load and randomize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACKATON image and segmentation data\n",
    "hackathon_dir = os.path.join(dirs[\"data\"], 'HACKATHON')\n",
    "map_fn = lambda x: (x[0], int(x[1]))\n",
    "with open(os.path.join(hackathon_dir, \"train.txt\"), 'r') as fp:\n",
    "    train_info_hackathon = [map_fn(entry.strip().split(',')) for entry in fp.readlines()]\n",
    "image_dir = os.path.join(hackathon_dir, 'images', 'train')\n",
    "seg_dir = os.path.join(hackathon_dir, 'segmentations', 'train')\n",
    "_train_data_hackathon = get_data_from_info(image_dir, seg_dir, train_info_hackathon)\n",
    "_train_data_hackathon = large_image_splitter(_train_data_hackathon, dirs[\"cache\"], 4, only_label_one=True)\n",
    "mixed_images = load_mixed_images(dirs[\"data\"])\n",
    "_train_data_hackathon.extend(mixed_images)\n",
    "#copy_list = transform_and_copy(_train_data_hackathon, dirs['cache'])\n",
    "#balance_training_data2(_train_data_hackathon, copy_list, seed=72)\n",
    "\n",
    "# One channel\n",
    "convert_labels(_train_data_hackathon, dtype=np.float32, as_array=True)\n",
    "# Two channel\n",
    "#convert_labels(_train_data_hackathon, dtype=np.int64, as_array=False)\n",
    "    \n",
    "# PSUF data\n",
    "\"\"\"psuf_dir = os.path.join(dirs[\"data\"], 'psuf')\n",
    "with open(os.path.join(psuf_dir, \"train.txt\"), 'r') as fp:\n",
    "    train_info = [entry.strip().split(',') for entry in fp.readlines()]\n",
    "image_dir = os.path.join(psuf_dir, 'images')\n",
    "train_data_psuf = get_data_from_info(image_dir, None, train_info)\"\"\"\n",
    "# Split data into train, validate and test\n",
    "train_split, test_data_hackathon = train_test_split(_train_data_hackathon, test_size=0.2, shuffle=True)#, random_state=42)\n",
    "#copy_list = transform_and_copy(train_split, dirs['cache'])\n",
    "#balance_training_data2(train_split, copy_list, seed=72)\n",
    "train_data_hackathon, valid_data_hackathon = train_test_split(train_split, test_size=0.2, shuffle=True)#, random_state=43)\n",
    "\n",
    "#convert_labels(train_data_hackathon, dtype=np.int64, as_array=False)\n",
    "#convert_labels(valid_data_hackathon, dtype=np.int64, as_array=False)\n",
    "#convert_labels(test_data_hackathon, dtype=np.int64, as_array=False)\n",
    "\n",
    "#balance_training_data(train_data_hackathon, seed=72)\n",
    "#balance_training_data(valid_data_hackathon, seed=73)\n",
    "#balance_training_data(test_data_hackathon, seed=74)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-strip",
   "metadata": {},
   "source": [
    "## Setup transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop foreground\n",
    "crop_foreground = CropForegroundd(\n",
    "    keys=[\"image\"],\n",
    "    source_key=\"image\",\n",
    "    margin=(5, 5, 0),\n",
    "    select_fn = lambda x: x != 0\n",
    ")\n",
    "# Crop Z\n",
    "crop_z = RelativeCropZd(keys=[\"image\"], relative_z_roi=(0.05, 0.15))\n",
    "\n",
    "# Window width and level (window center)\n",
    "WW, WL = 1500, -600\n",
    "ct_window = CTWindowd(keys=[\"image\"], width=WW, level=WL)\n",
    "# Random flip axis\n",
    "rand_x_flip = RandFlipd(keys=[\"image\"], spatial_axis=0, prob=0.50)\n",
    "rand_y_flip = RandFlipd(keys=[\"image\"], spatial_axis=1, prob=0.50)\n",
    "rand_z_flip = RandFlipd(keys=[\"image\"], spatial_axis=2, prob=0.50)\n",
    "# Rand affine transform\n",
    "rand_affine = RandAffined(\n",
    "    keys=[\"image\"],\n",
    "    prob=0.50,\n",
    "    rotate_range=(0, 0, np.pi/12),\n",
    "    shear_range=(0.07, 0.07, 0.0),\n",
    "    translate_range=(0, 0, 0),\n",
    "    scale_range=(0.07, 0.07, 0.0),\n",
    "    padding_mode=\"zeros\"\n",
    ")\n",
    "# Pad image to have hight at least 30\n",
    "spatial_pad = SpatialPadd(keys=[\"image\"], spatial_size=(-1, -1, 30))\n",
    "# Resize image x and y\n",
    "resize_fator = 0.50\n",
    "xy_size = int(512*resize_fator)\n",
    "#resize = Resized(keys=[\"image\"], spatial_size=(int(512*resize_fator), int(512*resize_fator), -1), mode=\"trilinear\")\n",
    "resize1 = Resized(keys=[\"image\"], spatial_size=(-1, -1, 40), mode=\"area\")\n",
    "resize2 = Resized(keys=[\"image\"], spatial_size=(xy_size, xy_size, -1), mode=\"area\")\n",
    "# spatioal crop\n",
    "crop = SpatialCropd(keys=[\"image\"], roi_start=(0, 0, 4), roi_end=(xy_size, xy_size, 36))\n",
    "# Apply Gaussian noise\n",
    "rand_gaussian_noise = RandGaussianNoised(keys=[\"image\"], prob=0.25, mean=0.0, std=0.05)\n",
    "# gaussian smooth\n",
    "gaussian_noise_smooth = GaussianSmoothd(keys=[\"image\"], sigma=(0.2, 0.2, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-coral",
   "metadata": {},
   "source": [
    "#### Create transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_transform = Compose([\n",
    "    LoadImaged(keys=[\"image\"]),\n",
    "    ct_window,\n",
    "    CTSegmentation(keys=[\"image\"]),\n",
    "    AddChanneld(keys=[\"image\"]),\n",
    "    crop_foreground,\n",
    "    #crop_z,\n",
    "    gaussian_noise_smooth,\n",
    "    resize1,\n",
    "    resize2,\n",
    "    crop,\n",
    "])\n",
    "hackathon_train_transform = Compose([\n",
    "    common_transform,\n",
    "    rand_x_flip,\n",
    "    rand_y_flip,\n",
    "    rand_z_flip,\n",
    "    rand_affine,\n",
    "    rand_gaussian_noise,\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "]).flatten()\n",
    "hackathon_valid_transfrom = Compose([\n",
    "    common_transform,\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "]).flatten()\n",
    "hackathon_test_transfrom = Compose([\n",
    "    common_transform,\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "]).flatten()\n",
    "psuf_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\"]),\n",
    "    AddChanneld(keys=[\"image\"]),\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-europe",
   "metadata": {},
   "source": [
    "## Number of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-aggregate",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "valid_data = []\n",
    "tl = len(train_data_hackathon)\n",
    "vl = int(tl * 0.2)\n",
    "for i in range(num_models):\n",
    "    train_data.append(train_data_hackathon[:(vl*i)] + train_data_hackathon[(vl*(i+1)):tl])\n",
    "    valid_data.append(train_data_hackathon[(vl*i): (vl*(i+1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-metadata",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_determinism(seed=100)\n",
    "train_datasets = [PersistentDataset(data=train_data[i], transform=hackathon_train_transform, cache_dir=dirs[\"persistent\"]+f\"_train_{i}\") for i in range(num_models)]\n",
    "valid_datasets = [PersistentDataset(data=valid_data[i], transform=hackathon_valid_transfrom, cache_dir=dirs[\"persistent\"]+f\"_valid_{i}\") for i in range(num_models)]\n",
    "test_dataset = PersistentDataset(data=test_data_hackathon[:], transform=hackathon_test_transfrom, cache_dir=dirs[\"persistent\"])\n",
    "_, n, p = calculate_class_imbalance(train_data_hackathon)\n",
    "train_loaders = [DataLoader(\n",
    "    train_datasets[i],\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    pin_memory=using_gpu,\n",
    "    num_workers=2,\n",
    "    #sampler=ImbalancedDatasetSampler(train_data_hackathon, num_samples=2*p, callback_get_label=lambda x, i: x[i]['_label']),\n",
    "    collate_fn=PadListDataCollate(Method.SYMMETRIC, NumpyPadMode.CONSTANT)\n",
    ") for i in range(num_models)]\n",
    "_, n, p = calculate_class_imbalance(valid_data_hackathon)\n",
    "valid_loaders = [DataLoader(\n",
    "    valid_datasets[i],\n",
    "    batch_size=2,\n",
    "    pin_memory=using_gpu,\n",
    "    num_workers=2,\n",
    "    #sampler=ImbalancedDatasetSampler(valid_data_hackathon, num_samples=2*p, callback_get_label=lambda x, i: x[i]['_label']),\n",
    "    collate_fn=PadListDataCollate(Method.SYMMETRIC, NumpyPadMode.CONSTANT)\n",
    ") for i in range(num_models)]\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=2,\n",
    "    pin_memory=using_gpu,\n",
    "    num_workers=2,\n",
    "    collate_fn=PadListDataCollate(Method.SYMMETRIC, NumpyPadMode.CONSTANT)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-aircraft",
   "metadata": {},
   "source": [
    "## Create network, loss function, optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 1\n",
    "def create_model():\n",
    "    #network = nets.EfficientNetBN(\"efficientnet-b4\", spatial_dims=3, in_channels=1, num_classes=out_channels).to(device)\n",
    "    network = nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=out_channels).to(device)\n",
    "    # pos_weight for class imbalance\n",
    "    _, n, p = calculate_class_imbalance(train_data_hackathon)\n",
    "    print(n, p)\n",
    "    ##############################################################\n",
    "    # One channel\n",
    "    pos_weight = torch.Tensor([n/p]).to(device)\n",
    "    loss_function = torch.nn.BCEWithLogitsLoss(pos_weight)\n",
    "    # Two channel\n",
    "    #pos_weight = torch.Tensor([n, p]).to(device)\n",
    "    #loss_function = torch.nn.CrossEntropyLoss(pos_weight)\n",
    "    ##############################################################\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95, last_epoch=-1)\n",
    "    return {'net': network, 'loss_fn': loss_function, 'opt': optimizer, 'lr_sch': scheduler}\n",
    "\n",
    "models = [create_model() for i in range(num_models)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-coaching",
   "metadata": {},
   "source": [
    "## Setup validator and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_post_transforms = Compose([\n",
    "    Activationsd(keys=\"pred\", sigmoid=True),\n",
    "    #Activationsd(keys=\"pred\", softmax=True),\n",
    "])\n",
    "def train(i, time):\n",
    "    model = models[i]\n",
    "    # Setup validator and trainer\n",
    "    validator = Validator(\n",
    "        device=device,\n",
    "        val_data_loader=valid_loaders[i],\n",
    "        network=model['net'],\n",
    "        loss_function=model['loss_fn'],\n",
    "        post_transform=valid_post_transforms,\n",
    "        n_classes=out_channels,\n",
    "        patience=15,\n",
    "        amp=using_gpu,\n",
    "        non_blocking=using_gpu\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        device=device,\n",
    "        out_dir=dirs[\"out\"],\n",
    "        out_name=f\"DenseNet121_ensamble_{i}\", # {i} je pomembna!!\n",
    "        max_epochs=60,\n",
    "        validation_epoch = 1,\n",
    "        validation_interval = 1,\n",
    "        train_data_loader=train_loaders[i],\n",
    "        network=model['net'],\n",
    "        optimizer=model['opt'],\n",
    "        loss_function=model['loss_fn'],\n",
    "        lr_scheduler=model['lr_sch'],\n",
    "        validator=validator,\n",
    "        amp=using_gpu,\n",
    "        non_blocking=using_gpu\n",
    "    )\n",
    "    validator.early_stop_handler.set_trainer(trainer)\n",
    "    trainer.run(time)\n",
    "    return model['net']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-survey",
   "metadata": {},
   "source": [
    "## Run trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "trained_networks = [train(i, now) for i in range(num_models)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-offer",
   "metadata": {},
   "source": [
    "## Setup ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_post_transforms = Compose([\n",
    "    MeanEnsembled(\n",
    "        keys=[\"pred0\", \"pred1\", \"pred2\", \"pred3\", \"pred4\"],\n",
    "        output_key=\"pred\",\n",
    "        # in this particular example, we use validation metrics as weights\n",
    "        weights=[1, 1, 1, 1, 1],\n",
    "    ),\n",
    "    Activationsd(keys=\"pred\", sigmoid=True),\n",
    "])\n",
    "val_handlers = [\n",
    "    StatsHandler(output_transform=lambda x: None),\n",
    "]\n",
    "if out_channels > 1:\n",
    "    to_onehot = AsDiscrete(to_onehot=True, n_classes=2)\n",
    "else:\n",
    "    to_onehot = lambda x: x\n",
    "tester = EnsembleEvaluator(\n",
    "    device=device,\n",
    "    val_data_loader=test_loader,\n",
    "    pred_keys=[\"pred0\", \"pred1\", \"pred2\", \"pred3\", \"pred4\"],\n",
    "    networks=trained_networks,\n",
    "    post_transform=mean_post_transforms,\n",
    "    key_val_metric={\"Test_AUC\": ROCAUC(average=\"micro\", output_transform=lambda x: (x[\"pred\"], to_onehot(x[\"label\"])))},\n",
    "    additional_metrics={\"Test_ACC\": Accuracy(output_transform=lambda x: (AsDiscrete(threshold_values=True)(x[\"pred\"]), to_onehot(x[\"label\"])))},\n",
    "    val_handlers=val_handlers,\n",
    "    amp=using_gpu,\n",
    "    non_blocking=using_gpu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-patch",
   "metadata": {},
   "source": [
    "## Run tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-adoption",
   "metadata": {},
   "source": [
    "## Setup tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tester = Tester(\n",
    "    device=device,\n",
    "    test_data_loader=test_loader,\n",
    "    load_dir=train_output,\n",
    "    out_dir=dirs[\"out\"],\n",
    "    network=network,\n",
    "    n_classes=out_channels,\n",
    "    post_transform=valid_post_transforms,\n",
    "    non_blocking=using_gpu,\n",
    "    amp=using_gpu\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-large",
   "metadata": {},
   "source": [
    "## Run tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tester.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = Activations(sigmoid=True) # One channel\n",
    "#act = Activations(softmax=True)  # Two channel\n",
    "#d = AsDiscrete(threshold_values=True)\n",
    "test_outputs_global = [[] for i in range(num_models)]\n",
    "test_labels_global = [[] for i in range(num_models)]\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        for i in range(num_models):\n",
    "            trained_networks[i].eval()\n",
    "            test_images, test_labels = test_data[\"image\"].to(device), test_data[\"label\"].to(device)\n",
    "            test_outputs = act(trained_networks[i](test_images))\n",
    "            test_outputs = test_outputs.detach().cpu().numpy().ravel()\n",
    "            test_labels = test_labels.detach().cpu().numpy().ravel()\n",
    "            test_outputs_global[i].extend(test_outputs.tolist())\n",
    "            test_labels_global[i].extend(test_labels.tolist())\n",
    "\n",
    "test_outputs_global = np.transpose(np.array(test_outputs_global))\n",
    "test_labels_global = np.transpose(np.array(test_labels_global))\n",
    "test_outputs_mean = np.empty(0)\n",
    "test_outputs_d = np.empty(0)\n",
    "d = lambda x: 1 if (x > 0.5) else 0\n",
    "for a in test_outputs_global:\n",
    "    m = np.mean(a)\n",
    "    test_outputs_mean = np.append(test_outputs_mean, m)\n",
    "    test_outputs_d = np.append(test_outputs_d, d(m))\n",
    "for i in range(len(test_outputs_mean)):\n",
    "    print(test_outputs_mean[i], test_outputs_d[i], test_labels_global[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-twins",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-festival",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"rain_loss = np.hsplit(np.loadtxt(os.path.join(train_output, 'log_loss.txt')), 2)\n",
    "valid_loss = np.hsplit(np.loadtxt(os.path.join(train_output, 'log_Valid_Loss.txt')), 2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fig, ax = plt.subplots()\n",
    "ax.plot(train_loss[0], train_loss[1], valid_loss[0], valid_loss[1])\n",
    "ax.set(xlabel='interation', ylabel='loss',\n",
    "       title='Loss')\n",
    "ax.grid()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-rocket",
   "metadata": {},
   "source": [
    "#### AUC and ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"valid_auc = np.hsplit(np.loadtxt(os.path.join(train_output, 'log_Valid_AUC.txt')), 2)\n",
    "valid_acc = np.hsplit(np.loadtxt(os.path.join(train_output, 'log_Valid_ACC.txt')), 2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fig, ax = plt.subplots()\n",
    "ax.plot(valid_auc[0], valid_auc[1], valid_acc[0], valid_acc[1])\n",
    "ax.set(xlabel='interation', ylabel='AUC and ACC',\n",
    "       title='AUC and ACC')\n",
    "ax.grid()\n",
    "plt.show()\"\"\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

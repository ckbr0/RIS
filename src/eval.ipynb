{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "satellite-consistency",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import monai.networks.nets as nets\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    AddChanneld,\n",
    "    CropForegroundd,\n",
    "    ToTensord,\n",
    "    RandFlipd,\n",
    "    RandAffined,\n",
    "    SpatialPadd,\n",
    "    Activationsd,\n",
    "    Activations,\n",
    "    Resized,\n",
    "    AsDiscreted,\n",
    "    AsDiscrete,\n",
    "    GaussianSmoothd,\n",
    "    SpatialCropd,\n",
    ")\n",
    "from transforms import (\n",
    "    CTWindowd,\n",
    "    CTSegmentation,\n",
    "    RelativeCropZd,\n",
    "    RandGaussianNoised,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, PersistentDataset, CacheDataset\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from monai.transforms.croppad.batch import PadListDataCollate\n",
    "from monai.utils import NumpyPadMode, set_determinism\n",
    "from monai.utils.enums import Method\n",
    "from monai.config import print_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from trainer import Trainer\n",
    "from validator import Validator\n",
    "from tester import Tester\n",
    "from utils import (\n",
    "    multi_slice_viewer,\n",
    "    setup_directories,\n",
    "    get_data_from_info,\n",
    "    large_image_splitter,\n",
    "    calculate_class_imbalance,\n",
    "    create_device,\n",
    "    balance_training_data,\n",
    "    balance_training_data2,\n",
    "    transform_and_copy,\n",
    "    convert_labels,\n",
    "    load_mixed_images,\n",
    "    replace_suffix,\n",
    ")\n",
    "from test_data_loader import TestDataset\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-selling",
   "metadata": {},
   "source": [
    "## Setup directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = setup_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-forest",
   "metadata": {},
   "source": [
    "## Setup torch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass \"cuda\" to use the GPU\n",
    "device, using_gpu = create_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-television",
   "metadata": {},
   "source": [
    "## Load and randomize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACKATON image and segmentation data\n",
    "hackathon_dir = os.path.join(dirs[\"data\"], 'HACKATHON')\n",
    "image_dir = os.path.join(hackathon_dir, 'images', 'test')\n",
    "seg_dir = os.path.join(hackathon_dir, 'segmentations', 'test')\n",
    "test_image_files = glob.glob(os.path.join(image_dir, '*'))\n",
    "with open(os.path.join(hackathon_dir, \"train.txt\"), 'r') as fp:\n",
    "    train_info_hackathon = [(os.path.basename(entry), None) for entry in test_image_files]\n",
    "\n",
    "test_data_hackathon = get_data_from_info(image_dir, seg_dir, train_info_hackathon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-parking",
   "metadata": {},
   "source": [
    "## Setup transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop foreground\n",
    "crop_foreground = CropForegroundd(\n",
    "    keys=[\"image\"],\n",
    "    source_key=\"image\",\n",
    "    margin=(5, 5, 0),\n",
    "    select_fn = lambda x: x != 0\n",
    ")\n",
    "# Crop Z\n",
    "crop_z = RelativeCropZd(keys=[\"image\"], relative_z_roi=(0.05, 0.15))\n",
    "# Window width and level (window center)\n",
    "WW, WL = 1500, -600\n",
    "ct_window = CTWindowd(keys=[\"image\"], width=WW, level=WL)\n",
    "# Pad image to have hight at least 30\n",
    "spatial_pad = SpatialPadd(keys=[\"image\"], spatial_size=(-1, -1, 30))\n",
    "# Resize image x and y\n",
    "resize_fator = 0.50\n",
    "xy_size = int(512*resize_fator)\n",
    "#resize = Resized(keys=[\"image\"], spatial_size=(int(512*resize_fator), int(512*resize_fator), -1), mode=\"trilinear\")\n",
    "resize1 = Resized(keys=[\"image\"], spatial_size=(-1, -1, 40), mode=\"area\")\n",
    "resize2 = Resized(keys=[\"image\"], spatial_size=(xy_size, xy_size, -1), mode=\"area\")\n",
    "# spatioal crop\n",
    "crop = SpatialCropd(keys=[\"image\"], roi_start=(0, 0, 4), roi_end=(xy_size, xy_size, 36))\n",
    "# gaussian smooth\n",
    "gaussian_noise_smooth = GaussianSmoothd(keys=[\"image\"], sigma=(0.2, 0.2, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-syria",
   "metadata": {},
   "source": [
    "#### Create transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_transform = Compose([\n",
    "    LoadImaged(keys=[\"image\"]),\n",
    "    ct_window,\n",
    "    CTSegmentation(keys=[\"image\"]),\n",
    "    AddChanneld(keys=[\"image\"]),\n",
    "    crop_foreground,\n",
    "    #crop_z,\n",
    "    gaussian_noise_smooth,\n",
    "    resize1,\n",
    "    resize2,\n",
    "    crop,\n",
    "])\n",
    "hackathon_test_transfrom = Compose([\n",
    "    common_transform,\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "]).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-interest",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_determinism(seed=100)\n",
    "test_dataset = PersistentDataset(data=test_data_hackathon[:], transform=hackathon_test_transfrom, cache_dir=dirs[\"persistent\"])\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=2,\n",
    "    #shuffle=True,\n",
    "    pin_memory=using_gpu,\n",
    "    num_workers=2,\n",
    "    collate_fn=PadListDataCollate(Method.SYMMETRIC, NumpyPadMode.CONSTANT)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-variety",
   "metadata": {},
   "source": [
    "## Setup network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 1\n",
    "#network = nets.EfficientNetBN(\"efficientnet-b4\", spatial_dims=3, in_channels=1, num_classes=out_channels).to(device)\n",
    "network = nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=out_channels).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-victim",
   "metadata": {},
   "source": [
    "## Load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"DenseNet121_1_2021-04-17_15-35-18\"\n",
    "load_dir = os.path.join(dirs['out'], 'training', model_dir)\n",
    "network_path = glob.glob(os.path.join(load_dir, 'network_key_metric*'))[0]\n",
    "print(network_path)\n",
    "network.load_state_dict(torch.load(network_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-passing",
   "metadata": {},
   "source": [
    "## Run tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = Activations(sigmoid=True) # One channel\n",
    "#act = Activations(softmax=True)  # Two channel\n",
    "d = AsDiscrete(threshold_values=True)\n",
    "\n",
    "test_outputs_global = []\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images = test_data[\"image\"].to(device)\n",
    "        test_image_names = test_data[\"image_meta_dict\"][\"filename_or_obj\"]\n",
    "        test_outputs = act(network(test_images))\n",
    "        \n",
    "        _test_outputs = test_outputs.detach().cpu().numpy().ravel()\n",
    "        _test_image_names = [os.path.basename(f) for f in test_image_names]\n",
    "        out = np.array((_test_image_names,_test_outputs))\n",
    "        out = out.T.tolist()\n",
    "        test_outputs_global.extend(out)\n",
    "\n",
    "if not os.path.exists(dirs['results']):\n",
    "    os.mkdir(dirs['results'])\n",
    "results_file = os.path.join(dirs['results'], f'{model_dir}.txt')\n",
    "np.savetxt(results_file, test_outputs_global, delimiter=\",\", fmt='%s %.8s')\n",
    "print(test_outputs_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-transition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
